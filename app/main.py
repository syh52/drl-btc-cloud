import os
import json
import asyncio
import logging
from datetime import datetime, timezone
from typing import Dict, Any, Optional, List
from pathlib import Path

import uvicorn
import numpy as np
import pandas as pd
from fastapi import FastAPI, HTTPException, BackgroundTasks
from pydantic import BaseModel
from google.cloud import storage, secretmanager
from google.cloud import logging as cloud_logging
import ccxt

# å¯¼å…¥è®­ç»ƒç»„ä»¶ (éœ€è¦å°†trainç›®å½•æ·»åŠ åˆ°è·¯å¾„)
import sys
sys.path.append('/app/train')

try:
    from stable_baselines3 import PPO
    from train.btc_env import BTCTradingEnv
except ImportError as e:
    print(f"è­¦å‘Š: æ— æ³•å¯¼å…¥è®­ç»ƒæ¨¡å—: {e}")
    # åœ¨ç”Ÿäº§ç¯å¢ƒä¸­å¯èƒ½éœ€è¦å¦å¤–å¤„ç†


# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# å¦‚æœåœ¨GCPç¯å¢ƒä¸­ï¼Œä½¿ç”¨Cloud Logging
if os.getenv('GOOGLE_CLOUD_PROJECT'):
    client = cloud_logging.Client()
    client.setup_logging()


# APIè¯·æ±‚/å“åº”æ¨¡å‹
class TradingRequest(BaseModel):
    symbol: str = "BTCUSDT"
    interval: str = "1m"
    lookback: int = 60
    source: str = "mock"  # mock, binance_testnet


class TradingResponse(BaseModel):
    ts: int  # æ—¶é—´æˆ³
    price: float  # å½“å‰ä»·æ ¼
    action: float  # æ¨¡å‹å†³ç­– [-1, 1]
    position: float  # ç›®æ ‡æŒä»“æ¯”ä¾‹
    equity: float  # å½“å‰å‡€å€¼
    note: str = "paper-trade"


class HealthResponse(BaseModel):
    status: str
    model_loaded: bool
    gcs_connected: bool
    timestamp: str


class ModelManager:
    """æ¨¡å‹ç®¡ç†å™¨ - è´Ÿè´£åŠ è½½å’Œç®¡ç†PPOæ¨¡å‹"""
    
    def __init__(self, bucket_name: str, model_prefix: str = "models/ppo/"):
        self.bucket_name = bucket_name
        self.model_prefix = model_prefix
        self.model: Optional[PPO] = None
        self.model_path: Optional[str] = None
        self.last_update: Optional[datetime] = None
        
    async def load_latest_model(self) -> bool:
        """ä»GCSåŠ è½½æœ€æ–°æ¨¡å‹"""
        try:
            logger.info("ğŸ” æ­£åœ¨æŸ¥æ‰¾æœ€æ–°æ¨¡å‹...")
            
            # è¿æ¥GCS
            client = storage.Client()
            bucket = client.bucket(self.bucket_name)
            
            # åˆ—å‡ºæ‰€æœ‰æ¨¡å‹æ–‡ä»¶
            blobs = bucket.list_blobs(prefix=self.model_prefix)
            model_files = [blob for blob in blobs if blob.name.endswith('.zip')]
            
            if not model_files:
                logger.warning(f"âš ï¸ åœ¨ gs://{self.bucket_name}/{self.model_prefix} ä¸­æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶")
                return False
            
            # æŒ‰æ—¶é—´æ’åºï¼Œè·å–æœ€æ–°æ¨¡å‹
            latest_blob = max(model_files, key=lambda b: b.time_created)
            model_gcs_path = f"gs://{self.bucket_name}/{latest_blob.name}"
            
            logger.info(f"ğŸ“¦ æ‰¾åˆ°æœ€æ–°æ¨¡å‹: {model_gcs_path}")
            
            # ä¸‹è½½æ¨¡å‹åˆ°æœ¬åœ°ä¸´æ—¶ç›®å½•
            local_model_path = f"/tmp/{latest_blob.name.split('/')[-1]}"
            latest_blob.download_to_filename(local_model_path)
            
            logger.info(f"â¬‡ï¸ æ¨¡å‹å·²ä¸‹è½½åˆ°: {local_model_path}")
            
            # åŠ è½½PPOæ¨¡å‹
            self.model = PPO.load(local_model_path)
            self.model_path = model_gcs_path
            self.last_update = datetime.now(timezone.utc)
            
            logger.info(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ: {model_gcs_path}")
            
            # æ¸…ç†æœ¬åœ°æ–‡ä»¶
            if os.path.exists(local_model_path):
                os.remove(local_model_path)
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return False
    
    def is_loaded(self) -> bool:
        """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²åŠ è½½"""
        return self.model is not None


class DataProvider:
    """æ•°æ®æä¾›å™¨ - è·å–BTCä»·æ ¼æ•°æ®"""
    
    def __init__(self):
        self.exchange = None
        self.mock_data = self._generate_mock_data()
        
    def _generate_mock_data(self) -> pd.DataFrame:
        """ç”Ÿæˆæ¨¡æ‹Ÿä»·æ ¼æ•°æ®"""
        np.random.seed(int(datetime.now().timestamp()) % 1000)
        
        # ç”Ÿæˆæœ€è¿‘24å°æ—¶çš„1åˆ†é’Ÿæ•°æ®
        n_points = 24 * 60  # 24å°æ—¶ * 60åˆ†é’Ÿ
        
        # åŸºç¡€ä»·æ ¼å’Œéšæœºæ³¢åŠ¨
        base_price = 65000 + np.random.normal(0, 5000)
        returns = np.random.normal(0, 0.001, n_points)  # 0.1%æ ‡å‡†å·®
        
        prices = [base_price]
        for ret in returns[1:]:
            next_price = prices[-1] * (1 + ret)
            prices.append(max(next_price, 1000))  # æœ€ä½ä»·æ ¼1000
        
        # æ„å»ºOHLCVæ•°æ®
        data = []
        current_time = datetime.now(timezone.utc)
        
        for i, close_price in enumerate(prices):
            timestamp = current_time.timestamp() - (n_points - i) * 60
            
            # æ¨¡æ‹ŸOHLC
            open_price = prices[i-1] if i > 0 else close_price
            volatility = abs(returns[i])
            high_price = max(open_price, close_price) * (1 + volatility * np.random.uniform(0.5, 1.5))
            low_price = min(open_price, close_price) * (1 - volatility * np.random.uniform(0.5, 1.5))
            volume = np.random.uniform(100, 1000)
            
            data.append({
                'timestamp': int(timestamp * 1000),  # æ¯«ç§’æ—¶é—´æˆ³
                'open': open_price,
                'high': high_price,
                'low': low_price,
                'close': close_price,
                'volume': volume
            })
        
        df = pd.DataFrame(data)
        
        # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡ (ä¸è®­ç»ƒç¯å¢ƒä¿æŒä¸€è‡´)
        df['returns'] = df['close'].pct_change()
        df['ma_20'] = df['close'].rolling(20, min_periods=1).mean()
        df['ma_ratio'] = df['close'] / df['ma_20'] - 1
        
        return df.fillna(0)
    
    async def get_recent_candles(self, symbol: str, interval: str, limit: int = 100) -> pd.DataFrame:
        """è·å–æœ€è¿‘çš„Kçº¿æ•°æ®"""
        try:
            if symbol == "BTCUSDT" and interval == "1m":
                # ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ® (å–æœ€æ–°limitä¸ªæ•°æ®ç‚¹)
                recent_data = self.mock_data.tail(limit).copy()
                
                # æ›´æ–°æœ€æ–°ä»·æ ¼ (æ¨¡æ‹Ÿå®æ—¶å˜åŒ–)
                latest_price = recent_data.iloc[-1]['close']
                price_change = np.random.normal(0, 0.002)  # 0.2%æ ‡å‡†å·®
                new_price = latest_price * (1 + price_change)
                
                # æ·»åŠ æœ€æ–°æ•°æ®ç‚¹
                current_timestamp = int(datetime.now(timezone.utc).timestamp() * 1000)
                new_row = {
                    'timestamp': current_timestamp,
                    'open': latest_price,
                    'high': max(latest_price, new_price),
                    'low': min(latest_price, new_price),
                    'close': new_price,
                    'volume': np.random.uniform(100, 1000),
                    'returns': price_change,
                    'ma_20': recent_data['ma_20'].iloc[-1],  # ç®€åŒ–å¤„ç†
                    'ma_ratio': new_price / recent_data['ma_20'].iloc[-1] - 1
                }
                
                # ä½¿ç”¨pd.concatä»£æ›¿append
                new_df = pd.concat([recent_data, pd.DataFrame([new_row])], ignore_index=True)
                return new_df.tail(limit)
            
            else:
                raise ValueError(f"æš‚ä¸æ”¯æŒ {symbol} {interval}")
                
        except Exception as e:
            logger.error(f"âŒ è·å–ä»·æ ¼æ•°æ®å¤±è´¥: {e}")
            raise HTTPException(status_code=500, detail=f"æ•°æ®è·å–å¤±è´¥: {e}")


class TradingDecisionLogger:
    """äº¤æ˜“å†³ç­–æ—¥å¿—è®°å½•å™¨"""
    
    def __init__(self, bucket_name: str):
        self.bucket_name = bucket_name
        
    async def log_decision(self, decision_data: Dict[str, Any]):
        """è®°å½•äº¤æ˜“å†³ç­–åˆ°GCSå’Œæ ‡å‡†è¾“å‡º"""
        try:
            # è®°å½•åˆ°æ ‡å‡†è¾“å‡º (Cloud Loggingä¼šè‡ªåŠ¨æ”¶é›†)
            logger.info(f"ğŸ“Š äº¤æ˜“å†³ç­–: {json.dumps(decision_data, indent=2)}")
            
            # åŒæ—¶è®°å½•åˆ°GCSæ–‡ä»¶ (ä»¥æ—¥æœŸä¸ºå•ä½)
            current_date = datetime.now(timezone.utc).strftime('%Y-%m-%d')
            blob_path = f"logs/paper/{current_date}/decisions.jsonl"
            
            # è½¬æ¢ä¸ºJSONLæ ¼å¼
            log_line = json.dumps(decision_data) + "\n"
            
            # ä¸Šä¼ åˆ°GCS (è¿½åŠ æ¨¡å¼)
            client = storage.Client()
            bucket = client.bucket(self.bucket_name)
            blob = bucket.blob(blob_path)
            
            # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œå…ˆä¸‹è½½ç°æœ‰å†…å®¹
            existing_content = ""
            if blob.exists():
                existing_content = blob.download_as_text()
            
            # è¿½åŠ æ–°å†…å®¹
            new_content = existing_content + log_line
            blob.upload_from_string(new_content, content_type='text/plain')
            
            logger.info(f"âœ… å†³ç­–å·²è®°å½•åˆ°: gs://{self.bucket_name}/{blob_path}")
            
        except Exception as e:
            logger.error(f"âŒ å†³ç­–æ—¥å¿—è®°å½•å¤±è´¥: {e}")


# å…¨å±€å˜é‡
model_manager: Optional[ModelManager] = None
data_provider: Optional[DataProvider] = None
decision_logger: Optional[TradingDecisionLogger] = None

# æ¨¡æ‹Ÿäº¤æ˜“çŠ¶æ€
current_position = 0.0  # å½“å‰æŒä»“æ¯”ä¾‹
current_equity = 1.0   # å½“å‰å‡€å€¼ (ç›¸å¯¹äºåˆå§‹èµ„é‡‘)
trade_count = 0


# FastAPIåº”ç”¨
app = FastAPI(title="DRL BTC Auto Trading API", version="1.0.0")


@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨æ—¶åˆå§‹åŒ–"""
    global model_manager, data_provider, decision_logger
    
    logger.info("ğŸš€ å¯åŠ¨DRL BTCè‡ªåŠ¨äº¤æ˜“æœåŠ¡...")
    
    # è·å–ç¯å¢ƒå˜é‡
    bucket_name = os.getenv("GCS_BUCKET_NAME", "your-bucket-name")
    
    # åˆå§‹åŒ–ç»„ä»¶
    model_manager = ModelManager(bucket_name)
    data_provider = DataProvider()
    decision_logger = TradingDecisionLogger(bucket_name)
    
    # å°è¯•åŠ è½½æœ€æ–°æ¨¡å‹
    try:
        model_loaded = await model_manager.load_latest_model()
        if model_loaded:
            logger.info("âœ… æ¨¡å‹å·²åœ¨å¯åŠ¨æ—¶åŠ è½½")
        else:
            logger.warning("âš ï¸ å¯åŠ¨æ—¶æœªèƒ½åŠ è½½æ¨¡å‹ï¼Œå°†åœ¨è¿è¡Œæ—¶é‡è¯•")
    except Exception as e:
        logger.error(f"âŒ å¯åŠ¨æ—¶æ¨¡å‹åŠ è½½å¤±è´¥: {e}")


@app.get("/health", response_model=HealthResponse)
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    gcs_connected = False
    try:
        # æµ‹è¯•GCSè¿æ¥
        client = storage.Client()
        # ç®€å•çš„è¿æ¥æµ‹è¯•
        list(client.list_buckets())
        gcs_connected = True
    except:
        pass
    
    return HealthResponse(
        status="healthy" if model_manager and model_manager.is_loaded() else "degraded",
        model_loaded=model_manager.is_loaded() if model_manager else False,
        gcs_connected=gcs_connected,
        timestamp=datetime.now(timezone.utc).isoformat()
    )


@app.post("/tick", response_model=TradingResponse)
async def trading_tick(request: TradingRequest, background_tasks: BackgroundTasks):
    """å¤„ç†äº¤æ˜“å†³ç­–è¯·æ±‚"""
    global current_position, current_equity, trade_count
    
    logger.info(f"ğŸ“ˆ æ”¶åˆ°äº¤æ˜“å†³ç­–è¯·æ±‚: {request.symbol} {request.interval}")
    
    try:
        # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²åŠ è½½
        if not model_manager or not model_manager.is_loaded():
            logger.warning("âš ï¸ æ¨¡å‹æœªåŠ è½½ï¼Œå°è¯•é‡æ–°åŠ è½½...")
            if model_manager:
                model_loaded = await model_manager.load_latest_model()
                if not model_loaded:
                    raise HTTPException(status_code=503, detail="æ¨¡å‹æœªåŠ è½½ï¼Œè¯·ç¨åé‡è¯•")
            else:
                raise HTTPException(status_code=503, detail="æ¨¡å‹ç®¡ç†å™¨æœªåˆå§‹åŒ–")
        
        # è·å–æœ€æ–°ä»·æ ¼æ•°æ®
        candles = await data_provider.get_recent_candles(
            request.symbol, 
            request.interval, 
            request.lookback + 20  # å¤šè·å–ä¸€äº›æ•°æ®ä»¥è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
        )
        
        if len(candles) < request.lookback:
            raise HTTPException(status_code=400, detail=f"å¯ç”¨æ•°æ®ä¸è¶³ï¼Œéœ€è¦è‡³å°‘{request.lookback}æ ¹Kçº¿")
        
        # å‡†å¤‡è§‚æµ‹æ•°æ® (ä¸è®­ç»ƒç¯å¢ƒä¸€è‡´)
        recent_candles = candles.tail(request.lookback)
        
        # æ„å»ºç‰¹å¾çŸ©é˜µ
        features = []
        for _, row in recent_candles.iterrows():
            feature_vector = [
                row['open'],
                row['high'],
                row['low'],
                row['close'],
                row['volume'],
                row['returns'] if not np.isnan(row['returns']) else 0.0
            ]
            features.append(feature_vector)
        
        obs = np.array(features, dtype=np.float32)
        
        # å½’ä¸€åŒ–å¤„ç† (ä¸è®­ç»ƒç¯å¢ƒä¿æŒä¸€è‡´)
        if len(obs) > 0:
            latest_close = obs[-1, 3]
            obs[:, :4] = obs[:, :4] / latest_close - 1.0  # ä»·æ ¼å½’ä¸€åŒ–
            obs[:, 4] = np.log1p(obs[:, 4]) / 10.0      # æˆäº¤é‡å½’ä¸€åŒ–
        
        # æ¨¡å‹é¢„æµ‹
        action, _ = model_manager.model.predict(obs[None, :], deterministic=True)
        target_position = np.clip(action[0], -1.0, 1.0)
        
        # è®¡ç®—å½“å‰ä»·æ ¼å’Œæ—¶é—´æˆ³
        current_price = candles.iloc[-1]['close']
        current_timestamp = int(candles.iloc[-1]['timestamp'])
        
        # æ›´æ–°çº¸é¢äº¤æ˜“çŠ¶æ€
        position_change = abs(target_position - current_position)
        if position_change > 0.01:  # ä»“ä½å˜åŒ–è¶…è¿‡1%
            trade_count += 1
        
        # ç®€åŒ–çš„æƒç›Šè®¡ç®— (å®é™…åº”è¯¥åŸºäºä»·æ ¼å˜åŒ–)
        price_return = candles.iloc[-1]['returns'] if not np.isnan(candles.iloc[-1]['returns']) else 0.0
        current_equity *= (1 + current_position * price_return - position_change * 0.001)  # æ‰£é™¤æ‰‹ç»­è´¹
        
        # æ›´æ–°æŒä»“
        current_position = target_position
        
        # æ„å»ºå“åº”
        response = TradingResponse(
            ts=current_timestamp,
            price=current_price,
            action=float(target_position),
            position=float(current_position),
            equity=float(current_equity),
            note="paper-trade"
        )
        
        # å¼‚æ­¥è®°å½•å†³ç­–æ—¥å¿—
        decision_data = {
            "timestamp": current_timestamp,
            "symbol": request.symbol,
            "interval": request.interval,
            "price": current_price,
            "action": float(target_position),
            "position": float(current_position),
            "equity": float(current_equity),
            "trade_count": trade_count,
            "model_path": model_manager.model_path,
            "note": "paper-trade"
        }
        
        background_tasks.add_task(decision_logger.log_decision, decision_data)
        
        logger.info(f"âœ… å†³ç­–å®Œæˆ: ä»·æ ¼={current_price:.2f}, åŠ¨ä½œ={target_position:.3f}, æŒä»“={current_position:.3f}")
        
        return response
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ äº¤æ˜“å†³ç­–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"äº¤æ˜“å†³ç­–å¤±è´¥: {str(e)}")


@app.get("/status")
async def get_status():
    """è·å–æœåŠ¡çŠ¶æ€ä¿¡æ¯"""
    return {
        "model_loaded": model_manager.is_loaded() if model_manager else False,
        "model_path": model_manager.model_path if model_manager and model_manager.is_loaded() else None,
        "last_model_update": model_manager.last_update.isoformat() if model_manager and model_manager.last_update else None,
        "current_position": current_position,
        "current_equity": current_equity,
        "trade_count": trade_count,
        "server_time": datetime.now(timezone.utc).isoformat()
    }


@app.post("/reload_model")
async def reload_model():
    """æ‰‹åŠ¨é‡æ–°åŠ è½½æ¨¡å‹"""
    if not model_manager:
        raise HTTPException(status_code=503, detail="æ¨¡å‹ç®¡ç†å™¨æœªåˆå§‹åŒ–")
    
    logger.info("ğŸ”„ æ‰‹åŠ¨é‡æ–°åŠ è½½æ¨¡å‹...")
    model_loaded = await model_manager.load_latest_model()
    
    if model_loaded:
        return {"status": "success", "message": "æ¨¡å‹é‡æ–°åŠ è½½æˆåŠŸ", "model_path": model_manager.model_path}
    else:
        raise HTTPException(status_code=500, detail="æ¨¡å‹é‡æ–°åŠ è½½å¤±è´¥")


if __name__ == "__main__":
    # æœ¬åœ°å¼€å‘æ—¶çš„å¯åŠ¨é…ç½®
    port = int(os.getenv("PORT", 8080))
    
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=port,
        log_level="info",
        reload=os.getenv("ENV") == "development"
    )